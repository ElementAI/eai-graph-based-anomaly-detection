# Documentation: 'prediction_unb2017' experiment

This experiment pipeline uses network flows in the form of tabular data, generates graph representations of the data, 
predicts anomalies and generates prediction metrics. Both deep graph embeddings and Refex&Rolx techniques are supported 
to generate node embeddings, on which a OC-SVM is used to perform anomaly detection. The pipelines has been tested with 
the UNB2017 and UNSWNB15 datasets. 

DAG: 

    setup_experiment >> create_training_dataset
    setup_experiment >> create_inference_dataset
    create_training_dataset >> train_graph_model
    create_inference_dataset >> create_graph_model_node_embeddings
    train_graph_model >> create_graph_model_node_embeddings
    create_graph_model_node_embeddings >> infer_predictions
    infer_predictions >> create_interval_metrics
    if skip_node_analysis is False:
        create_graph_model_node_embeddings >> node_analysis

##create_training_dataset / create_inference_dataset

This task uses Pandas dataframes to create graphs for each time interval. 

### Parameters: 
- start
- end
- interval_width
- interval_overlap
- graph_representation
- feature_extractor

### input_files:

#### raw_file

Raw files compatible with the currrent pipeline:
    dataset_files/unb2017/raw/unb2017.h5
    tests/test_data/unb2017/tinyunb2017.h5

##### UNB2017
Columns: ['Destination IP', 'Destination Port', 'Flow Duration', 'Flow ID', 'Label', 'Protocol', 'Source IP', 'Source Port', 'Timestamp', 'Total Backward Packets', 'Total Fwd Packets', 'Adjusted Time']

tinyunb2017.h5

| index    |  Source IP    |  Source Port  |  Destination IP  | Destination Port | Protocol | Flow Duration | Flow ID |  Timestamp | Total Backward Packets | Total Fwd Packets | Label | Adjusted Time |
|----------|:-------------:|--------------:|-----------------:|-----------------:|------:|------:|----:|-------:|----:|-----------:|------:|----------:|
| 2017-07-03 08:55:58   |  8.254.250.126   |   80       |   192.168.10.5   |  49188 | 6 | 4 |192.168.10.5-8.254.250.126-49188-80-6| 2017-07-03 08:55:58 | 0       | 0| BENIGN | 2017-07-03 08:55:58 |
| 2017-07-03 08:55:58   |  8.254.250.126   |   80       |   192.168.10.5   |  49188 | 6 | 1 |192.168.10.5-8.254.250.126-49188-80-6| 2017-07-03 08:55:58 | 0       | 0| BENIGN | 2017-07-03 08:55:58 |
...

### output_files:

The task generates a "FullData" object for each interval. The "FullData" class contains: 
- "x": Node feature matrix with shape [num_nodes, num_node_features]
- "y": Node label tensor [num_nodes, 1]. Values: BENIGN=1, MALICIOUS=-1, UNLABELLED=0
- "node_indexes_in_tensors": Node id tensor mapping their id (ex:"128.10.10.1") with their index in the x,y tensors [num_nodes, 2]

The "FullData" objects get saved to disk, using paths such as:

    /dataset_files/unb2017/processed/0d6c81023cc99090e6edd9dea0cf185b/2015-01-22 11:50:14_2015-01-22 11:55:14
    /dataset_files/unb2017/processed/0d6c81023cc99090e6edd9dea0cf185b/2015-01-22 11:50:14_2015-01-22 12:00:14


## train_graph_model 
This task uses Pandas dataframes to create graphs split by time intervals. 

### Parameters: 
- start
- end
- interval_width
- hidden_dim
- feature_extractor
- training_epochs
- predicator_name
- tensorboard_writer
- patience_epochs
- learning_rate

### input_files:
Uses as input files the files generated by the "create_training_dataset" task (i.e. "FullData" objects saved to disk).

### output_files:
trained_model: the trained pytorch model saved to disk, with the name: 'trained_model_' + cfg_name

## create_graph_model_node_embeddings 
This task uses a trained model to generate node embeddings at each interval.  

### Parameters: 
- start
- end
- interval_width
- predicator_name
- hidden_dim
- nodes_of_interest
- tensorboard_writer

### input_files:
- the files generated by the "create_inference_dataset" task (i.e. "FullData" objects saved to disk).
- the trained model generated by "train_graph_model"
 
### output_files:
node_embeddings: a pickled python dictionary containing an entry for each node. The key is the node id, such as 
"192.168.10.10" and the value is a list of embeddings, with one element per interval. Each embeddings element is itself 
a list of values.

For example, 2 nodes with embeddings of size 3 over 2 epochs: 

    {'192.168.10.10': [[0.1521, 0.0001, 0.0002],[0.2354, 0.0005, 0.0002]],
     '192.168.10.11': [[0.1221, 0.0111, 0.0022],[0.2222, 0.0025, 0.0302]]}

## Predict
Uses node embeddings to train a OC-SVM and predict if at each interval, each node is an outlier or not.

### Parameters: 
- start
- end
- interval_width
- svm_training_technique
- nodes_of_interest
- reference_victim_node
- tensorboard_writer
- airflow_vars

### input_files:
- the files generated by the "create_inference_dataset" task (i.e. "FullData" objects saved to disk).
- node_embeddings: pickled python dictionary created by "create_graph_model_node_embeddings"
- trained_model: trained pytorch model created by the task "train_graph_model"

### output_files:
- prediction_df: Pandas dataframe containing the OC-SVM prediction for each node at each interval 
(plus ground truth if available)
- df_metrics: Pandas dataframe containing node information such as the 'baseline_embeddings', 'embeddings', 'class_label'
'timestamp', 'interval_duration', 'interval_idx', 'cosine' (cosine distance from baseline). 

## Create_interval_metrics

Creates metrics using intervals. 

### Parameters: 
- interval_width
- title

### input_files:
prediction_df: 


### output_files:
- grid_png: Generates a png file showing the prediction for each node at each interval, in the form of a grid. For 
labelled data, the following information is provided: TP, TN, FP, FN, Node Missing. For unlabelled data, the grid shows 
P, N and Node missing. 
- metrics_summary_file: a text file containing metrics such as accuracy, balanced accuracy, F1 score, confusion matrix, 
etc. Available for labelled data only. 

## Node_analysis
Provides in depth analysis of a specific subset of nodes (defined via nodes_of_interest in ini file). 

### Parameters: 
- experiment_name
- start
- end
- nodes_of_interest
- reference_nodes
- reference_victim_node

### input_files:
df_metrics: Pandas dataframe containing node data per interval (created by the 'Predict' task)

### output_files: 
- metrics_summary_file: Metrics for multiple SVM settings
- df_detailed_classifier_data
- df_roc_classifier_data
- embedding plots with ground truth for multiple SVM settings.  
- roc curves for multiple SVM settings.
